Building the project
====================

HTML-Workers
------------

Main goal of a worker is to generate static html pages, combining together all configuration files and jigs and after that upload them
to the CDN. It has two main working modes. The first is when the worker is connected to the rabbitMQ and for each event in the queue it generates one or more pages. On the second mode it can be triggered to generate one or more pages via command line arguments.

HTML worker executable file is `./worker/index.js`. To get the list of options you have to go to the `JigMagga` folder and execute `node worker -h` Here is the output:
```
Usage: worker [options]

  Options:

    -h, --help                    output usage information
    -j, --values [values]         specify values as JSON
    -v, --verbose                 whether to print to output all log information
    -b, --versionnumber [value]   specify build version as float
    -q, --queue                   start program to listen on queue
    -e, --errorqueue              use error queue
    -E, --errorerrorqueue         use errorerror queue
    -y, --staticold               generate all old static pages (sem)
    -d, --basedomain [value]      specify the domain
    -p, --page [value]            define the template to be generated
    -k, --childpage [value]       define a child page that should overwrite the parent element
    -x, --live                    use live db and queue - normally staging is used
    -X, --liveuncached            use live db and uncache queue
    -D, --deployuncached [value]  send uncache messages to the deploy queue
    -u, --url [value]             define the url to be generated
    -H, --highprio                use the high priority queue
    -M, --mediumprio              use the high priority queue
    -L, --lowprio                 use the high priority queue
    -V, --postfix                 use this version postfix queue
    -I, --locale <n>              use given locale
    -n, --namespace <n>           relative path from current dir to target project or just nane of project
    -f, --fixtures                use fixtures from project folder instead of making an api call
    -w, --write                   write to disk the archive with generated files instead of upload them, path should be provided
    -B, --bucket [value]          will override the config bucket and upload to this bucket you parse as value
    -P, --prefetch <n>            amount of prefetched messages from queue, makes sens only wirh -q
    --longjohn                    enable longjohn module for stack traces
    --tag [value]                 allows to filter logs from current worker
```

There are two use cases for HTML-worker:
- Listening on amqp queue and generating and uploading pages based on messages that are coming.
- Generate and upload some pages based on parameters with what the worker was started.

### Working with a Queue###

If you want to connect your worker to an amqp server you have to use -q (or --queue) flag and specify the credentials of your amqp
server. For instance `node worker -n yournamespace -d domain -q`. After starting worker connects to three different queues:
- **mainQueue** is used for obtaining messages with pages that should be generated by worker, each message should be in json format and have basedomain, page and url fields,
- **errorQueue**, the worker push the message to this queue, if some error with some message happened
- **doneQueue**, worker will push a message to this queue after the message is generated and ready for uploading

Name of the main queue is calculated in the following way: [queueBaseName]+[baseDomainName]+[prefix]. queueBaseName can be changed in
the config, baseDomainName is set by setting -d (--basedomain flag). The prefix can be set in the config and they mainly stand for the priority of the queue. If no prefix
is specified, then the prefix will be `deploy`. All of them can be changed in the config. By default there are three priority (prefix) keys that add a prefix: -H (--highprio), -M (--mediumprio), -L (--lowprio).

Name of the error queue is calculated in the same way as for main, but it always contains the error prefix inside. Name of the "done" queue
is always 'pages.generate.done'.
mainQueue:
By default if you start worker like that: `node worker -n yournamespace -q` it will connect to next queues
```
mainQueue: pages.generate.deploy
errorQueue: pages.generate.error.deploy
doneQueue: pages.generate.done
```


```
  node worker -n yournamespace -q -H

  // mainQueue: pages.generate.high
  // errorQueue: pages.generate.error.high
  // doneQueue: pages.generate.done
  
  node worker -n yournamespace -q -H -d foo.com
  
  // mainQueue: pages.generate.foo.com.high
  // errorQueue: pages.generate.foo.com.error.high
  // doneQueue: pages.generate.done
```

When worker connects to the queue it grabs (prefetch) by default 50 messages in one time and generate pages for them in parallel. Sometimes it's necessary to reduce amount of prefetched messages because if pages are huge it could cause performance issues. To do that you can set `-P` or `--prefetch` flag.

`node worker -n yournamespace -q -H -d foo.com -P 3` will prefetch only 3 messages in one time.

Another useful parameter is a `versionnumber` if it exists and has some value generated pages will dependent of js and css of this particular version. If versionnumber is not set it will be taken from version.json file that is in the root folder of the project.

For instance:
`node worker -n yournamespace -q -H -d foo.com --versionnumber 2.7.2` 

#### Error flow

If there is some error in worker it pushs the message that causes the error to error queue. After the issue is fixed you probably want to regenerate all messages in error queue for doing this you can connect your worker to error queue. For instance You had one worker for domain foo.com with high priority after some time it generated some error message and pushed them to `pages.generate.foo.com.error.high` To generate this pages you can start the same worker with additional -e flag:

`node worker -n yournamespace -q -H -d foo.com -e`

If errors will appear again in error worker they will come to `pages.generate.foo.com.error.error.high` queue. In order to connect worker to this queue do:
`node worker -n yournamespace -q -H -d foo.com -E`.
And if there is again some errors they will go back to `pages.generate.foo.com.error.high`


#### Message parameters
Worker support two message content types: `text/plain` and `text/json`. But exact message has to be only in json format. Below you can find a list of fields that could present in message:
- *basedomain* should be in each message. Means for what domain generated page belongs
- *page* and *url*. Page is responsible for specifying page type that will be generated, url used for non static pages and value will be used for page url generation. Those parameters are not mandatory if there is no page and url in message. The worker will grab a list of pages from config that are not dependent on url parameter(static pages) and will generate all of them.
- *locale*. If present the page will be generated only for this locale, if not the worker will generate pages for all locales that are available for this page in config.
- *childpage*. Used for specify childpage type.

All other fileds that finished on Id(cityId, linkId etc.) is used by worker for api calls.

Here is some message example:
```
{
    "cityId": 123,
    "url": "berlin-10115",
    "basedomain": "lieferando.de",
    "page": "service"
}

{
    "restaurantId": 12345,
    "url": "restaurnt-name",
    "basedomain": "lieferando.de",
    "page": "menu"
}
```

### Generating some page directly with worker without queue###
One of use cases of such usage of worker is the generation of static pages. Static page is a page with a URL that does not depend of data that is in this page.
For instance the index and imprint pages are static.

For instance in order to generate and then upload all the static pages in the domain `you.domain.com` in the project with namespace
`namespace`, you have to do following:

`node worker -n namespace -d you.domain.com`

In order to generate just the index page and upload it you should specify `-p` or `--page` flag:

`node worker -n namespace -d you.domain.com -p index`

If you want to do the same but without uploading and just save the result on disk (for testing propose), do following:

`node worker -n namespace -d you.domain.com -p index -w`

Some time you have to generate some non static page for instance menu page for some restaurant. For that page you have to specify the url and restaurantId you can do it like this:

`node worker -n namespace -d you.domain.com -p menu -u "restaurnt-name" -j "{\"restaurantId\": 12345}"`

As you see `-j` or `--values` it's a key that accept any json value and use it like a data for all api calls.

### Worker Configuration###

All worker configuration files should be at the `config` folder that should be at the root of project inside JigMagga. If you have just
generated a project you can find in this folder these files:

- *amqp.json* - a file with amqp credentials, where you can define to what amqp server you worker has to connect and how it should calculate the name of the queue
- *api.json* - config with api server credentials
- *fixtures.json* - list of mappings between api requests and files with fixture data
- *main.json* - config with cdn api credentials, logger parameters and some other stuff

If you want to specify some different values from some other environment you should just create a file with this environment
in the name, rewrite some key and set the NODE_ENV environment variable. For instance if you want to connect to some special amqp server in live environment you have to create a file with name `amqp.live.json` specify in it just what you want to override and than set NODE_ENV
before you invoke the worker:

`NODE_ENV=live node worker -n namespace -d you.domain.com`


###Uploading pages to the CDN###
Currently html worker can upload resources to CDN's that are compatible with the Amazon S3 API. All credentials can be specified in the
main file inside knox namespace.

>Note: If you do not want to upload the file(s), you have to specify -w flag which means that your goal is to save the generated files to disk.

Bucket name can be set by setting the S3_BUCKET key. In this case all files of your project will be uploaded to this bucket. If you want to have one bucket per each domain, you have to set the S3_BUCKET key to false (or just delete this key),
and specify your buckets for the live and stage environments. For instance if in your project you have two domains `foo.com` and `m.foo.com`, your buckets config could be like this:
   "buckets": {
       "live": {
           "foo.com": "www.live-bucket.com",
           "m.foo.com": "m.live-bucket.com"
       },
       "stage": {
           "foo.com": "stage.bucket.com",
           "m.foo.com": "stage.m.bucket.com"
       }
   }
If you don't specify your buckets in the config file, bucket name will be calculated as follows: If the live flag (-x --live or -X --liveuncached)
is present, the name will be www.{basedomain} where basedomain is obtained from the incoming message or from command line. If current env is not live the bucket name will be stage.{basedomain}. Bucket name also could be set by `-B` or `--bucket` option, for example if you start worker like below:

`node worker -q -n namespace -d domain.com -B bucket.name.com`

This worker will connect to a queue and upload all generated pages to the `bucket.name.com` bucket.
